{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeUD/fZvVn7WUZF2qbj0UF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbberylll/ESAA/blob/main/%EC%88%98%EC%83%81%EC%9E%91_%EB%A6%AC%EB%B7%B02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용한 데이터 & 주제 설명\n",
        "대회 주제: 은행 고객이 target=1인 거래를 했는지를 예측 (이진 분류 문제)\n",
        "데이터 특성:\n",
        "1. 익명화된 200개의 변수 (var_0 ~ var_199)\n",
        "2. 각 row는 하나의 고객 정보\n",
        "3. 불균형 데이터: target=1 비율이 매우 낮음"
      ],
      "metadata": {
        "id": "Qk9KuvI3TRgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기법 적용\n",
        "1. 모델: LightGBM (Gradient Boosting 기반 모델)\n",
        "2. 전처리: 간단한 통계 기반 EDA 후 바로 모델 학습\n",
        "3. Validation: Stratified K-Fold Cross Validation (5-fold)\n",
        "\n",
        "예측 결과 평균을 이용해 submission 생성"
      ],
      "metadata": {
        "id": "JoNJnYp0TZfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 접근 방식\n",
        "단순하고 강력한 방식으로 접근:\n",
        "\n",
        "EDA는 가볍게 진행\n",
        "복잡한 feature engineering 없이 raw feature 그대로 사용\n",
        "모델 성능 향상을 위해 cross validation 반복 + 평균 ensemble\n",
        "\n",
        "**정확도보다 AUC(Area Under Curve) 향상에 초점**"
      ],
      "metadata": {
        "id": "77xjPHJiThP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 코드 흐름 요약\n",
        "\n",
        "\n",
        "### (1) EDA\n",
        "```\n",
        "train.describe()\n",
        "train['target'].value_counts(normalize=True)\n",
        "train.corr()['target'].sort_values(ascending=False)\n",
        "```\n",
        "\n",
        "\n",
        "데이터 분포, 타겟 불균형 확인\n",
        "변수 간 상관관계는 거의 없음 → 익명화된 feature 간 해석 불가\n",
        "\n",
        "### (2) Feature Engineering & Processing\n",
        "\n",
        "```\n",
        "# 별도 Feature Engineering 없음\n",
        "# 모든 var_ 변수를 그대로 사용\n",
        "X = train.drop(['target', 'ID_code'], axis=1)\n",
        "y = train['target']\n",
        "```\n",
        "\n",
        "### (3) 모델링 (LightGBM + StratifiedKFold)\n",
        "\n",
        "```\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=44000)\n",
        "for train_idx, valid_idx in folds.split(X, y):\n",
        "    lgb_train = lgb.Dataset(X.iloc[train_idx], label=y.iloc[train_idx])\n",
        "    lgb_valid = lgb.Dataset(X.iloc[valid_idx], label=y.iloc[valid_idx])\n",
        "    \n",
        "    clf = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_valid],\n",
        "                    early_stopping_rounds=100, verbose_eval=100)\n",
        "```\n",
        "\n",
        "### (4) 예측 후 앙상블\n",
        "\n",
        "```\n",
        "predictions += clf.predict(test_X, num_iteration=clf.best_iteration) / folds.n_splits\n",
        "```"
      ],
      "metadata": {
        "id": "X6wTulijTonC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 차별점 (유의미한 포인트)\n",
        "\n",
        "1. 복잡한 Feature Engineering 없이도 좋은 성능 달성\n",
        "\n",
        "  → raw feature와 LGBM만으로도 고성능이 가능하다는 점을 증명\n",
        "\n",
        "2. 불균형 데이터에서 Stratified K-Fold 적용\n",
        "\n",
        "  → target=1 비율이 매우 적어 class 분포를 고려한 validation 필수\n",
        "\n",
        "3. Ensemble 기법 없이도 단순 평균으로 안정성 확보"
      ],
      "metadata": {
        "id": "myB35QSCUQMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 배울 점 요약\n",
        "\n",
        "1. 접근 방식\t: EDA와 모델링 사이의 균형, Overfitting 방지를 위한 early stopping\n",
        "2. 모델 선택\t: Tabular 데이터에 적합한 LightGBM 사용\n",
        "3. Validation\t: 불균형 데이터일수록 Stratified KFold의 필요성 증가\n",
        "4. 단순함\t: 불필요한 변수 생성보다 정제된 CV + 튜닝이 더 중요할 수 있음"
      ],
      "metadata": {
        "id": "q9kckrXkUd2b"
      }
    }
  ]
}