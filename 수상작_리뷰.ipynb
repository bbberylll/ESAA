{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlxHoM9he5tB86kZ+h02b1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbberylll/ESAA/blob/main/%EC%88%98%EC%83%81%EC%9E%91_%EB%A6%AC%EB%B7%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spaceship Titanic 수상작 리뷰\n",
        "\n",
        "## 사용한 데이터 & 주제 설명\n",
        "### 대회 목표\n",
        ": 우주선 탑승객 생존 여부(Transported: True/False) 예측 (이진 분류)\n",
        "\n",
        "### 데이터 구성:\n",
        "- 승객 정보 및 탑승 기록 (ex. PassengerId, HomePlanet, CryoSleep, Cabin, Destination, Age, VIP, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, Transported)\n",
        "\n",
        "- 범주형 + 수치형 변수 혼합\n",
        "\n",
        "- 다수 결측치 존재, 특성 공학(피처 엔지니어링) 중요\n",
        "\n",
        "### 평가지표\n",
        ": Accuracy 또는 AUC"
      ],
      "metadata": {
        "id": "2xwkGFH6H4-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 어떤 기법이 적용됐는지?\n",
        "\n",
        "### 모델:\n",
        "- XGBoost Classifier\n",
        "- LightGBM Classifier\n",
        "\n",
        "### 블렌딩 방식:\n",
        "- soft voting 전략 (확률 예측을 가중 평균)\n",
        "- 블렌딩 계수는 검증 데이터 기반 조정\n",
        "\n",
        "### Preprocessing:\n",
        "- 결측치 imputation (Age, Cabin 구분 등)\n",
        "- 범주형 변수 인코딩 (Label Enc, One-Hot)\n",
        "- 파생변수 생성 (Deck, NumRooms, TotalSpend 등)"
      ],
      "metadata": {
        "id": "6n2cJlU6IIFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 접근 방식\n",
        "\n",
        "### 데이터 전처리\n",
        "1. Cabin 문자열에서 데크 분리 (Deck, NumCabin)\n",
        "2. GroupID 생성 (동일한 스택 탑승객별 그룹)\n",
        "3. 지출 관련 피쳐 통합 및 로그 스케일링\n",
        "4. 결측치 처리: 예를 들어 Age의 중앙값 대체, CryoSleep 결측 시 False 등\n",
        "\n",
        "### 특성 엔지니어링\n",
        "1. TotalSpend = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck (지출 합계 변수)\n",
        "2. HasCabin, Deck, NumCabin 등 특징적 파생 피쳐 생성\n",
        "\n",
        "### 모델 훈련\n",
        "1. 스태티파이드 K-Fold 또는 간이 validation set 생성\n",
        "2. XGBoost, LightGBM 각각 훈련 및 검증\n",
        "\n",
        "### 블렌딩\n",
        "1. 검증 데이터를 활용해 최적 가중치 탐색 (예: [0.6 * XGB + 0.4 * LGBM])\n",
        "2. 테스트 데이터에 동일 가중치 적용 후 평균 예측"
      ],
      "metadata": {
        "id": "ZTlRxhWsIUU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 코드 흐름 요약\n",
        "\n",
        "### 데이터 로딩 & 전처리\n",
        "```\n",
        "df = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "# Cabin에서 Deck 추출\n",
        "df['Deck'] = df['Cabin'].map(lambda x: x.split('/')[0] if pd.notna(x) else 'Unknown')\n",
        "\n",
        "# 그룹 ID\n",
        "df['GroupID'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
        "\n",
        "# 파생 변수\n",
        "spend_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
        "df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
        "df['LogSpend'] = np.log1p(df['TotalSpend'])\n",
        "```\n",
        "\n",
        "### 모델 훈련\n",
        "```\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[features]\n",
        "y = df['Transported'].astype(int)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "xgb = XGBClassifier(...)\n",
        "lgb = LGBMClassifier(...)\n",
        "xgb.fit(X_train, y_train)\n",
        "lgb.fit(X_train, y_train)\n",
        "\n",
        "pred_xgb = xgb.predict_proba(X_valid)[:,1]\n",
        "pred_lgb = lgb.predict_proba(X_valid)[:,1]\n",
        "```\n",
        "\n",
        "### 블렌딩 (검증 기반 가중 평균)\n",
        "```\n",
        "blend_pred = 0.6 * pred_xgb + 0.4 * pred_lgb\n",
        "# 최적 가중치 계산 (예: grid search)\n",
        "```\n",
        "\n",
        "### 테스트 예측 및 제출\n",
        "```\n",
        "pred_xgb_test = xgb.predict_proba(test[features])[:,1]\n",
        "pred_lgb_test = lgb.predict_proba(test[features])[:,1]\n",
        "final_test_pred = 0.6 * pred_xgb_test + 0.4 * pred_lgb_test\n",
        "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Transported': final_test_pred > 0.5})\n",
        "```"
      ],
      "metadata": {
        "id": "pmIPkfBwIkEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 차별점 (유의미한 포인트)\n",
        "파생변수 기반 feature engineering이 블렌딩 성능을 뒷받침\n",
        "예: TotalSpend, Deck 같은 유의미한 값들이 모델 간 보완력을 높임\n",
        "\n",
        "Soft voting 블렌딩으로 안정성 강한 예측\n",
        "단일 모델 대비 과적합 방지 및 안정적 성능\n",
        "\n",
        "가중치 튜닝: validation 기반으로 XGB 중심 또는 LGB 중심 가중치를 유동적으로 조절 가능"
      ],
      "metadata": {
        "id": "gV8ZpfByJCBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 배울 점 요약\n",
        "Blending 전략: Soft-voting 블렌딩은 stacking보다 구현이 간단하면서도 실전에서 활용되는 주요 앙상블 방법\n",
        "\n",
        "Feature Importance 극대화: 파생변수의 퀄리티가 앙상블 효과를 극대화\n",
        "\n",
        "가중치 최적화 방법: 검증 기반 그리드 검색으로 블렌딩 가중치 조정"
      ],
      "metadata": {
        "id": "1bqagYR8JEwY"
      }
    }
  ]
}